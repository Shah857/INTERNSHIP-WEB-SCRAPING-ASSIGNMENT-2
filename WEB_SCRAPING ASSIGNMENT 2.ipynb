{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db992add",
   "metadata": {},
   "source": [
    "#                             WEB SCRAPING - ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1def72e4",
   "metadata": {},
   "source": [
    "# Q.1 \n",
    "\n",
    "Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563eb815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing Selenium\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe96415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb60a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the webpage https://www.naukri.com/\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://www.naukri.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5294c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter “Data Analyst” in “Skill, Designations, Companies” field\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82486dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter “Bangalore” in “enter the location” field\n",
    "\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div/div[7]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1004a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the search button\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e09efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating List\n",
    "Job_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Experience_Required=[]\n",
    "Salary_Offered=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6184a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the data for the first 10 jobs results using relative XPATH\n",
    "\n",
    "title_tag=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tag[0:10]:\n",
    "    title=i.text\n",
    "    Job_Title.append(title)\n",
    "\n",
    "location_tag=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tag[0:10]:\n",
    "    location=i.text\n",
    "    Job_Location.append(location)\n",
    "\n",
    "company_tag=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tag[0:10]:\n",
    "    company=i.text\n",
    "    Company_Name.append(company)\n",
    "\n",
    "experience_tag=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tag[0:10]:\n",
    "    experience=i.text\n",
    "    Experience_Required.append(experience)\n",
    "\n",
    "salary_tag=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft \"]')\n",
    "for i in salary_tag[0:10]:\n",
    "    salary=i.text\n",
    "    Salary_Offered.append(salary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe of scraped Data\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':Job_Title[0:10],'Location':Job_Location[0:10],'Company':Company_Name[0:10],'Experience Required':Experience_Required[0:10],'Salary Offered':Salary_Offered[0:10]})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f3b89",
   "metadata": {},
   "source": [
    "# Q.2\n",
    "Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "    \n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c599d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e426d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the webpage https://www.naukri.com Using Safari/chrome Driver\n",
    "#driver_next= webdriver.Safari()\n",
    "\n",
    "#getting the webpage https://www.naukri.com/\n",
    "driver_next=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver_next.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19fa1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter “Data Scientist” in “Skill, Designations, Companies” field Using CLASS NAME\n",
    "desig=driver_next.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "desig.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1739d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter \"Bangalore” in “enter the location” field using absolute XPATH.\n",
    "loc=driver_next.find_element(By.XPATH,\"/html/body/div/div[7]/div/div/div[5]/div/div/div/input\")\n",
    "loc.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcfa78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the search button.\n",
    "search_next=driver_next.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search_next.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73cb64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating LIST\n",
    "Job_desig=[]\n",
    "Job_Loc=[]\n",
    "Company_Nam=[]\n",
    "Experience_Reqd=[]\n",
    "Salary_Ofrd=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219db74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the data for the first 10 jobs results you get for DESIGNATOIN,LOCATION,COMPANY,EXPERIENCE & SALARY using Relative XPATH.\n",
    "\n",
    "desig_tag=driver_next.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in desig_tag[0:10]:\n",
    "    title_new=i.text\n",
    "    Job_desig.append(title_new)\n",
    "\n",
    "loc_tag=driver_next.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in loc_tag[0:10]:\n",
    "    location_new=i.text\n",
    "    Job_Loc.append(location_new)\n",
    "\n",
    "comp_tag=driver_next.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in comp_tag[0:10]:\n",
    "    company_new=i.text\n",
    "    Company_Nam.append(company_new)\n",
    "\n",
    "exp_tag=driver_next.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in exp_tag[0:10]:\n",
    "    experience_new=i.text\n",
    "    Experience_Reqd.append(experience_new)\n",
    "\n",
    "sal_tag=driver_next.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft \"]')\n",
    "for i in sal_tag[0:10]:\n",
    "    salary_new=i.text\n",
    "    Salary_Ofrd.append(salary_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8411065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Dataframe of the scraped data\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Job Title':Job_desig,'Location':Job_Loc,'Company':Company_Nam,'Experience Required':Experience_Reqd,'Salary Offered':Salary_Ofrd})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23d5563",
   "metadata": {},
   "source": [
    "#    Q.4\n",
    "    Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes: \n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077286b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a8fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the webpage https://www.flipkart.com/\n",
    "driver_new=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver_new.get(\"https://www.flipkart.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing sunglasses\n",
    "category=driver_new.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "category.send_keys('Sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adcbf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the search button.\n",
    "search_item=driver_new.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search_item.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating LIST\n",
    "Brand_Name=[]\n",
    "Product=[]\n",
    "Price=[]\n",
    "Discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec81ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the first 3 page on website\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    brands=driver_new.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brands[0:100]:\n",
    "        brands_t=i.text\n",
    "        Brand_Name.append(brands_t)\n",
    "    \n",
    "    products=driver_new.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in products[0:100]:\n",
    "        products_t=i.text\n",
    "        Product.append(products_t)\n",
    "    \n",
    "    prices=driver_new.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in prices[0:100]:\n",
    "        price_t=i.text\n",
    "        Price.append(price_t)\n",
    "    \n",
    "    discounts=driver_new.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in discounts[0:100]:\n",
    "        discount_t=i.text\n",
    "        Discount.append(discount_t)\n",
    "        \n",
    "    next_button=driver_new.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee35d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating DataFrame for first 100 sunglasses.\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Brand':Brand_Name[0:100],'Product Description':Product[0:100],'Price':Price[0:100],'Discount':Discount[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd2832",
   "metadata": {},
   "source": [
    "# Q.5\n",
    "\n",
    "Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb/product- reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market place=FLIPKART\n",
    "    \n",
    "    As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7108fcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1953b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the provided link\n",
    "driver_review=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver_review.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907404d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating list\n",
    "Rating=[]\n",
    "Review_Summary=[]\n",
    "Full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9bbfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the first 3 page on website to scrape the first 100 rating,Review Summary,Full_review of the provided link\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    ratings=driver_review.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in ratings[0:100]:\n",
    "        review_t=i.text\n",
    "        Rating.append(review_t)\n",
    "    \n",
    "    summary=driver_review.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in summary[0:100]:\n",
    "        summary_t=i.text\n",
    "        Review_Summary.append(summary_t)\n",
    "    \n",
    "    Full_summary=driver_review.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in Full_summary[0:100]:\n",
    "        full_summary_t=i.text\n",
    "        Full_review.append(full_summary_t)\n",
    "\n",
    "    next_button_review=driver_review.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button_review.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e027ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Rating':Rating[0:100],'Review Summary':Review_Summary[0:100],'Full Review Summary':Full_review[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62db1af5",
   "metadata": {},
   "source": [
    "# Q6: \n",
    "Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa277fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63794686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the webpage https://www.flipkart.com/\n",
    "driver_sneakers=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver_sneakers.get(\"https://www.flipkart.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing sneakers\n",
    "category_sneakers=driver_sneakers.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "category_sneakers.send_keys('Sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2e48a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##click the search button.\n",
    "search_item_sneakers=driver_sneakers.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search_item_sneakers.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc4bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating List\n",
    "Brand_sneakers=[]\n",
    "Product_desc_sneakers=[]\n",
    "Price_sneakers=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad39bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape data for first 100 sneakers with provided attributes using relative XPATH.\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    b_sneakers=driver_sneakers.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in b_sneakers[0:100]:\n",
    "        brandnew_sneakers=i.text\n",
    "        Brand_sneakers.append(brandnew_sneakers)\n",
    "    \n",
    "    p_sneakers=driver_sneakers.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in p_sneakers[0:100]:\n",
    "        pro_sneakers=i.text\n",
    "        Product_desc_sneakers.append(pro_sneakers)\n",
    "    \n",
    "    price_sneak=driver_sneakers.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_sneak[0:100]:\n",
    "        pricenew_sneak=i.text\n",
    "        Price_sneakers.append(pricenew_sneak)\n",
    "    \n",
    "    next_button_sneakers=driver_sneakers.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button_sneakers.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966112d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Brand_sneakers),len(Product_desc_sneakers),len(Price_sneakers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc44edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Brand':Brand_sneakers[0:100],'Product Description':Product_desc_sneakers[0:100],'Price':Price_sneakers[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f695feb1",
   "metadata": {},
   "source": [
    "# Q.7\n",
    "Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop: \n",
    "1. Title\n",
    "2. Ratings \n",
    "3. Price        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb4b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ebd9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the webpage https://www.amazon.com/\n",
    "driver_laptop=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver_laptop.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#listing Laptop using relative xpATH\n",
    "lap=driver_laptop.find_element(By.XPATH,\"//div[@class='nav-search-field ']//input\")\n",
    "lap.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff02d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on Search\n",
    "search_lap=driver_laptop.find_element(By.XPATH,'//span[@class=\"nav-search-submit-text nav-sprite nav-progressive-attribute\"]//input')\n",
    "search_lap.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fcaab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating List\n",
    "laptop_desc=[]\n",
    "laptop_rating=[]\n",
    "laptop_price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cd3b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the first 3 page on website to scrape the first 100 laptop's Title, Rating and Price from amazon using relative XPATH\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    laptop_d=driver_laptop.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "    for i in laptop_d[0:100]:\n",
    "        laptop_description=i.text\n",
    "        laptop_desc.append(laptop_description)\n",
    "    \n",
    "    laptop_r=driver_laptop.find_elements(By.XPATH,'//span[@class=\"a-size-base\"]')\n",
    "    for i in laptop_r[0:100]:\n",
    "        lap_rate=i.text\n",
    "        laptop_rating.append(lap_rate)\n",
    "    \n",
    "    laptop_p=driver_laptop.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "    for i in laptop_p[0:100]:\n",
    "        lap_pri=i.text\n",
    "        laptop_price.append(lap_pri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6741a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Description':laptop_desc[0:10],'Rating':laptop_rating[0:10],'Price':laptop_price[0:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0d1647",
   "metadata": {},
   "source": [
    "# Q.8\n",
    "Write a python program to scrape data for Top 1000 Quotes of All Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118d0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e58dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_quote=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver_quote.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcabefca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SITE CANT BE REACHED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845b0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb95c191",
   "metadata": {},
   "source": [
    "# Q.9\n",
    "Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574dd2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b9f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting provided webpage\n",
    "driver_GK=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver_GK.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0285bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding 'GK' in page and go to the link\n",
    "category_first=driver_GK.find_element(By.XPATH,'/html/body/div/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[9]/a')\n",
    "category_first.send_keys('GK')\n",
    "search_item_GK=driver_GK.find_element(By.XPATH,'/html/body/div/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[9]/a')\n",
    "search_item_GK.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe8f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding List of all prime Ministers of India\n",
    "category_second=driver_GK.find_element(By.XPATH,'/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a')\n",
    "category_second.send_keys('List of all Prime Ministers of India')\n",
    "search_item_pmall=driver_GK.find_element(By.XPATH,'/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a')\n",
    "search_item_pmall.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0663e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating List\n",
    "PM_NAME=[]\n",
    "PM_BORN_DEAD=[]\n",
    "TERM=[]\n",
    "REMARKS=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f56419",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tag=driver_GK.find_elements(By.XPATH,\"/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[5]/span/div[3]/table/tbody/tr[2]/td[2]/p//strong/a\")\n",
    "for i in name_tag[0:15]:\n",
    "    name=i.text\n",
    "    PM_NAME.append(name)\n",
    "\n",
    "BD_tag=driver_GK.find_elements(By.XPATH,\"/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[5]/span/div[3]/table/tbody/tr[2]/td[3]/p\")\n",
    "for i in BD_tag[0:15]:\n",
    "    born=i.text\n",
    "    PM_BORN_DEAD.append(born)\n",
    "\n",
    "Term_tag=driver_GK.find_elements(By.XPATH,\"/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[5]/span/div[3]/table/tbody/tr[2]/td[4]/p[1]/span\")\n",
    "for i in Term_tag[0:15]:\n",
    "    pm_term=i.text\n",
    "    TERM.append(pm_term)\n",
    "\n",
    "remarks_tag=driver_GK.find_elements(By.XPATH,\"/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[5]/span/div[3]/table/tbody/tr[2]/td[5]/p\")\n",
    "for i in remarks_tag[0:15]:\n",
    "    pm_remarks=i.text\n",
    "    REMARKS.append(pm_remarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959a2aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating DataFrame\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'PM NAME':PM_NAME,'BORN-DEAD':PM_BORN_DEAD,'TERM':TERM,'REMARKS':REMARKS})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efddb85",
   "metadata": {},
   "source": [
    "# Q.10\n",
    "Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9864258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_motor=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver_motor.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d877409",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list=driver_motor.find_element(By.XPATH,'/html/body/div[4]/div[1]/div[3]/ul/li[6]/ul/li[1]/a')\n",
    "category_list.send_keys('Lists')\n",
    "search_item_list=driver_motor.find_element(By.XPATH,'/html/body/div[4]/div[1]/div[3]/ul/li[6]/ul/li[1]/a')\n",
    "search_item_list.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2003d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_listitem=driver_motor.find_element(By.XPATH,'/html/body/div[3]/div[9]/div[1]/div[1]/div/div/div[5]/div/div[1]/h3/a')\n",
    "category_listitem.send_keys('50 Most Expensive Cars In The World')\n",
    "search_item_listitem=driver_motor.find_element(By.XPATH,'/html/body/div[3]/div[9]/div[1]/div[1]/div/div/div[5]/div/div[1]/h3/a')\n",
    "search_item_listitem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2de4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Car_Name=[]\n",
    "Car_Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd35da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tag=driver_motor.find_elements(By.CLASS_NAME,\"subheader\")\n",
    "for i in brand_tag[0:50]:\n",
    "    b_name=i.text\n",
    "    Car_Name.append(b_name)\n",
    "\n",
    "price_tag=driver_motor.find_elements(By.XPATH,\"//strong\")\n",
    "for i in price_tag[0:50]:\n",
    "    price=i.text\n",
    "    Car_Price.append(price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c2c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'CAR BRAND NAME':Car_Name,'Price':Car_Price})\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
